{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from transformers import AutoProcessor, CLIPSegForImageSegmentation\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "# import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image as image\n",
    "\n",
    "from lib.config import cfg\n",
    "from lib.config import update_config\n",
    "from lib.utils.utils import create_logger, select_device, time_synchronized\n",
    "from lib.models import get_net\n",
    "from lib.dataset import LoadImages, LoadStreams\n",
    "from lib.core.general import non_max_suppression, scale_coords\n",
    "from lib.utils import plot_one_box,show_seg_result\n",
    "from lib.core.function import AverageMeter\n",
    "from lib.core.postprocess import morphological_process, connect_lane\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 2.1.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating runs\\BddDataset\\_2023-11-24-10-35\n",
      "origin size : (1080, 1920, 3)\n",
      "image 1/1 c:\\Users\\Faizan\\YOLOP\\frame1.jpg: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "logger, _, _ = create_logger(\n",
    "    cfg, cfg.LOG_DIR, 'demo')\n",
    "device = select_device(logger,'cpu')\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "model = get_net(cfg)\n",
    "checkpoint = torch.load(\"weights/End-to-end.pth\", map_location= device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "if half:\n",
    "    model.half()  # to FP16\n",
    "\n",
    "\n",
    "\n",
    "source = 'frame1.jpg'\n",
    "original_image =  cv2.imread(source)\n",
    "print('origin size :', cv2.imread(source).shape)\n",
    "dataset = LoadImages(source, img_size=640)\n",
    "\n",
    "# Choose one image from the dataset\n",
    "path, img, img_det, vid_cap, shapes = next(iter(dataset))\n",
    "\n",
    "# Transform the image\n",
    "img = transform(img).to(device)\n",
    "img = img.half() if half else img.float()\n",
    "\n",
    "# If the image has 3 dimensions, add one more dimension (batch dimension)\n",
    "if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "# Run the model\n",
    "det_out, da_seg_out, ll_seg_out = model(img)\n",
    "\n",
    "# Process the segmentation outputs\n",
    "print(len(det_out))\n",
    "inf_out, _ , _ = det_out\n",
    "det_pred = non_max_suppression(inf_out, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
    "det = det_pred[0]\n",
    "\n",
    "_, _, height, width = img.shape\n",
    "h, w, _ = img_det.shape\n",
    "\n",
    "pad_w, pad_h = shapes[1][1]\n",
    "pad_w = int(pad_w)\n",
    "pad_h = int(pad_h)\n",
    "ratio = shapes[1][0][1]\n",
    "\n",
    "da_predict = da_seg_out[:, :, pad_h:(height - pad_h), pad_w:(width - pad_w)]\n",
    "da_seg_mask = torch.nn.functional.interpolate(da_predict, scale_factor=int(1 / ratio), mode='bilinear')\n",
    "_, da_seg_mask = torch.max(da_seg_mask, 1)\n",
    "da_seg_mask = da_seg_mask.int().squeeze().cpu().numpy()\n",
    "\n",
    "ll_predict = ll_seg_out[:, :, pad_h:(height - pad_h), pad_w:(width - pad_w)]\n",
    "ll_seg_mask = torch.nn.functional.interpolate(ll_predict, scale_factor=int(1 / ratio), mode='bilinear')\n",
    "_, ll_seg_mask = torch.max(ll_seg_mask, 1)\n",
    "ll_seg_mask = ll_seg_mask.int().squeeze().cpu().numpy()\n",
    "\n",
    "# Process the segmentation masks and overlay them on the original image\n",
    "palette = np.random.randint(0, 255, size=(2, 2))\n",
    "palette[0] = [0, 0]\n",
    "palette[1] = [0, 255]\n",
    "palette = np.array(palette)\n",
    "assert palette.shape[0] == 2  # len(classes)\n",
    "assert palette.shape[1] == 2\n",
    "assert len(palette.shape) == 2\n",
    "\n",
    "result = (da_seg_mask, ll_seg_mask)\n",
    "color_area = np.zeros((result[0].shape[0], result[0].shape[1], 3), dtype=np.uint8)\n",
    "color_area[result[0] == 1] = [0, 255, 0]\n",
    "color_area[result[1] == 1] = [0, 255, 0]\n",
    "\n",
    "color_seg = color_area[..., ::-1]\n",
    "color_mask = np.mean(color_seg, 2)\n",
    "\n",
    "\n",
    "# img_r = cv2.resize(img_r, (1280, 720), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Display the result\n",
    "color_mask = cv2.resize(color_mask, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "result_image = original_image.copy()\n",
    "result_image[color_mask == 0] = 0\n",
    "\n",
    "cv2.imshow('Result Image', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
